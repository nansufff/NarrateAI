# NarrateAI
Audio Description Generation from Videos for the Visually Impaired 
This project aims to make visual media more accessible for visually impaired individuals by automatically generating detailed audio descriptions from videos.

Our system processes videos end-to-end:

Detects scene changes for temporal segmentation

Identifies key objects and activities using deep learning-based computer vision

Generates rich, natural-language descriptions using advanced language models

Converts the generated text into speech for audio output

Provides a user-friendly GUI with TalkBack support to ensure easy accessibility for visually impaired users

‚ú® Features:
Scene Detection: Automatically segments videos into meaningful scenes

Object Recognition: Identifies key elements in each frame

Caption Generation: Creates detailed and natural descriptions

Audio Narration: Translates text captions into clear, human-like audio

Accessible GUI: Designed with TalkBack compatibility for independent use

üõ†Ô∏è Technologies Used:
Python (TensorFlow, PyTorch, OpenCV)

Deep Learning (Computer Vision, NLP)

Scene Change Detection

Natural Language Generation

Text-to-Speech (gTTS)

Whisper for language detection

GUI Development

üìú How It Helps:
This project bridges the accessibility gap, enabling visually impaired users to engage with video content that was previously inaccessible. It demonstrates how AI can drive inclusion and make everyday experiences richer and more connected for everyone.

