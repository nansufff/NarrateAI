# ğŸ¥ NarrateAI

**Audio Description Generation from Videos for the Visually Impaired**

This project aims to make visual media more accessible for visually impaired individuals by automatically generating detailed audio descriptions from videos.


## ğŸ”¥ Our system processes videos end-to-end:
- **Detects scene changes** for temporal segmentation
- **Identifies key objects and activities** using deep learning-based computer vision
- **Generates rich, natural-language descriptions** using advanced language models
- **Converts the generated text into speech** for audio output
- **Provides a user-friendly GUI with TalkBack support** to ensure easy accessibility for visually impaired users


## âœ¨ Features
- **Scene Detection:** Automatically segments videos into meaningful scenes
- **Object Recognition:** Identifies key elements in each frame
- **Caption Generation:** Creates detailed and natural descriptions
- **Audio Narration:** Translates text captions into clear, human-like audio
- **Accessible GUI:** Designed with TalkBack compatibility for independent use


## ğŸ› ï¸ Technologies Used
- **Python** (TensorFlow, PyTorch, OpenCV)
- **Deep Learning** (Computer Vision, NLP)
- **Scene Change Detection**
- **Natural Language Generation**
- **Text-to-Speech** (gTTS)
- **Language Detection** (Whisper)
- **GUI Development**


## ğŸ“œ How It Helps
This project bridges the accessibility gap, enabling visually impaired users to engage with video content that was previously inaccessible.  
It demonstrates how AI can drive inclusion and make everyday experiences richer and more connected for everyone.


## ğŸš€ Team
- **Nandhana Suffin**
- **Niveditha B**
- **Nikhil Stephen**
- **Rachel Jacob**
![Screenshot 2025-04-18 110824](https://github.com/user-attachments/assets/5de9b636-7ee1-4169-a64f-12b288de8935)

